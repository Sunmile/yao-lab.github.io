{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ShakesBERT\n",
    "\n",
    "BERT's BertForNextSentencePrediction class gives a score for the likelihood that a sentence (or line) follows a preceding one. We can use this for example to construct a new sonnet from lines of existing Shakespeare sonnets. The new sonnet will have a higher likelihood of making sense than if we merely drew the lines at random. The next sentence prediction therefore acts as a kind of sense discriminator.\n",
    "\n",
    "Sonnet lines are taken from [Poetry DB](http://poetrydb.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertForNextSentencePrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:01<00:00, 140973.73B/s]\n"
     ]
    }
   ],
   "source": [
    "tokeniser = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall i compare thee to a summer's day?\n",
      "But sad mortality o'ersways their power,\n",
      "Spend'st thou thy fury on some worthless song,\n",
      "Use power with power, and slay me not by art,\n",
      "Now proud as an enjoyer, and anon\n",
      "When I break twenty? I am perjur'd most;\n",
      "There is such strength and warrantise of skill,\n",
      "Or ten times happier, be it ten for one;\n",
      "So is the time that keeps you as my chest,\n",
      "Than when her mournful hymns did hush the night,\n",
      "Making no summer of another's green,\n",
      "But bears it out even to the edge of doom.\n",
      "Then thank him not for that which he doth say,\n",
      "And gain by ill thrice more than I have spent.\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import json\n",
    "from random import *\n",
    "\n",
    "url = 'http://poetrydb.org/author,linecount/Shakespeare;14/lines'\n",
    "with urllib.request.urlopen(url) as response:\n",
    "    data = json.load(response)   \n",
    "\n",
    "    \n",
    "poem_number = randint(0, len(data)-1)\n",
    "#previous_line = data[poem_number]['lines'][0]\n",
    "previous_line=\"shall i compare thee to a summer's day?\\n\"\n",
    "print(previous_line.strip())\n",
    "\n",
    "next_line_prediction = 0\n",
    "threshold = 3\n",
    "poems_picked = [poem_number]\n",
    "\n",
    "for line_number in range(1, 14):\n",
    "    next_line_prediction = 0\n",
    "    while(line_number == len(poems_picked)):\n",
    "        poem_number = randint(0, len(data)-1)\n",
    "        line_to_check = data[poem_number]['lines'][line_number]\n",
    "        \n",
    "        len_line_1 = len(tokeniser.tokenize(previous_line))\n",
    "        len_line_2 = len(tokeniser.tokenize(line_to_check))\n",
    "\n",
    "        text = previous_line + ' ' + line_to_check\n",
    "        tokenized_text = tokeniser.tokenize(text)\n",
    "\n",
    "        indexed_tokens = tokeniser.convert_tokens_to_ids(tokenized_text)\n",
    "        segments_ids = ([0] * len_line_1) + ([1] * len_line_2)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        \n",
    "        predictions = model(tokens_tensor, segments_tensors)\n",
    "        \n",
    "        next_line_prediction = predictions[0,0].item()\n",
    "        # No poem should be taken a line from more than once\n",
    "        if poem_number not in poems_picked and next_line_prediction > threshold:\n",
    "            poems_picked = poems_picked + [poem_number]\n",
    "\n",
    "    print(line_to_check.strip())\n",
    "    previous_line = line_to_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chinese version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382072689/382072689 [01:32<00:00, 4135578.78B/s]\n"
     ]
    }
   ],
   "source": [
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-chinese')\n",
    "\n",
    "tokeniser = BertTokenizer.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('poems_clean.txt', \"r\", encoding='utf-8')\n",
    "poems = []\n",
    "for line in f.readlines():\n",
    "    title, poem = line.split(':')\n",
    "    poem = poem.replace('\\n', '') #将换行符去掉\n",
    "    poem=poem.split(' ')\n",
    "    for i in poem:\n",
    "        if len(i)==0:\n",
    "            poem.remove(i)\n",
    "    poems.append(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['寒随穷律变', '春逐鸟声开', '初风飘带柳', '晚雪间花梅', '碧林青旧竹', '绿沼翠新苔', '芝田初雁去', '绮树巧莺来', '']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "寒随穷律变\n"
     ]
    }
   ],
   "source": [
    "#Chinese version\n",
    "\n",
    "import urllib\n",
    "import json\n",
    "from random import *\n",
    "\n",
    "data=poems   \n",
    "poem_number = randint(0, len(data)-1)\n",
    "#previous_line = data[poem_number]['lines'][0]\n",
    "previous_line=\"寒随穷律变\\n\"\n",
    "print(previous_line.strip())\n",
    "\n",
    "next_line_prediction = 0\n",
    "threshold = 3\n",
    "poems_picked = [poem_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "goal=[]\n",
    "previous_line=\"寒随穷律变\"\n",
    "goal.append(previous_line)\n",
    "for line_number in range(1, 4):\n",
    "    next_line_prediction = 0\n",
    "    while(line_number == len(poems_picked)):\n",
    "        poem_number = randint(0, len(data)-1)\n",
    "        line_to_check = data[poem_number][line_number]\n",
    "        if len(line_to_check)==len(previous_line):\n",
    "            len_line_1 = len(tokeniser.tokenize(previous_line))\n",
    "            len_line_2 = len(tokeniser.tokenize(line_to_check))\n",
    "\n",
    "            text = previous_line + ' ' + line_to_check\n",
    "            tokenized_text = tokeniser.tokenize(text)\n",
    "\n",
    "            indexed_tokens = tokeniser.convert_tokens_to_ids(tokenized_text)\n",
    "            segments_ids = ([0] * len_line_1) + ([1] * len_line_2)\n",
    "            tokens_tensor = torch.tensor([indexed_tokens])\n",
    "            segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "            predictions = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "            next_line_prediction = predictions[0,0].item()\n",
    "            # No poem should be taken a line from more than once\n",
    "            if poem_number not in poems_picked and next_line_prediction > threshold:\n",
    "                poems_picked = poems_picked + [poem_number]\n",
    "                goal.append(line_to_check)\n",
    "                previous_line = line_to_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "寒随穷律变\n",
      "苒苒出蓬蒿\n",
      "从来悟明主\n",
      "月照海门秋\n"
     ]
    }
   ],
   "source": [
    "for i in goal:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
